{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fd57a1",
   "metadata": {},
   "source": [
    "# Jupyter IPykernel file code\n",
    "\n",
    "Set all relative paths and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Manage file imports with Jupyter and iPykernel\n",
    "notebook_dir = Path().resolve()\n",
    "project_dir = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_dir))\n",
    "sys.path.insert(0, str(notebook_dir))\n",
    "\n",
    "# Add src/ to sys.path\n",
    "src_path = project_dir / \"src\"\n",
    "if src_path.exists():\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a4132",
   "metadata": {},
   "source": [
    "# Initialize Variables\n",
    "- Set the LLM library.\n",
    "- Load the prompts from the YAML file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "today = datetime.today()\n",
    "llm = LLM()\n",
    "\n",
    "# Define input and output directories\n",
    "prompt_file_path = '../prompts'\n",
    "response_file_path = '../outputs/responses'\n",
    "presentation_file_path = '../outputs/presentations'\n",
    "pdf_file_path = '../outputs/pdfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cf5a535",
   "metadata": {},
   "source": [
    "### Prompt Chain 1. Basic news research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prompt_chain.utils.loader:Loaded 1 prompt file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prompt_chain.utils.loader:Loaded 5 prompts from ..\\prompts\n"
     ]
    }
   ],
   "source": [
    "# Import the structured response schema\n",
    "from projects.monday_briefing.schema import NewsInsightList, NewsReviewList, SummaryResponseList\n",
    "\n",
    "# Load all the prompts for the competitor news chain\n",
    "step=\"competitor\"\n",
    "prompts = load_prompts(\n",
    "    directory=prompt_file_path,\n",
    "    filename_pattern='news.yml',\n",
    "    filters={\"step\": step}\n",
    ")\n",
    "prompts_index = prompts.index()\n",
    "\n",
    "run_id = f\"monday_briefing_{today.month}.{today.day}.{str(today.year)[-2:]}\"\n",
    "\n",
    "news_prompt = prompts_index[step][\"news_research\"]\n",
    "news_prompt.run_id = run_id\n",
    "parse_prompt = prompts_index[step][\"news_parse\"]\n",
    "parse_prompt.run_id = run_id\n",
    "parse_prompt.response_format=NewsInsightList\n",
    "review_prompt = prompts_index[step][\"news_review\"]\n",
    "review_prompt.run_id = run_id\n",
    "review_prompt.response_format=NewsReviewList\n",
    "summary_prompt = prompts_index[step][\"summarize_news_topic\"]\n",
    "summary_prompt.run_id = run_id\n",
    "summary_prompt.response_format=SummaryResponseList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b85bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def company_news_chain(company):\n",
    "    #Search for news\n",
    "    news_response = llm.run_prompt(\n",
    "        prompt=news_prompt,\n",
    "        variables={\"company\": company},\n",
    "        context={\"company\": company}\n",
    "    )\n",
    "    news_response.save_to_file(base_dir=response_file_path, variable=company)\n",
    "\n",
    "    #Parse news\n",
    "    report=news_response.text\n",
    "    citations=news_response.citations.as_markdown_list()\n",
    "    parse_response = llm.run_prompt(\n",
    "        prompt=parse_prompt,\n",
    "        variables={\n",
    "            \"company\": company,\n",
    "            \"report\": report,\n",
    "            \"citations\": citations\n",
    "        },\n",
    "        context={\"company\": company},\n",
    "        citations=news_response.citations\n",
    "    )\n",
    "    parse_response.save_to_file(base_dir=response_file_path, variable=company)\n",
    "\n",
    "    #Review news for relevance and likely date\n",
    "    review_response = llm.run_prompt(\n",
    "        prompt=review_prompt,\n",
    "        variables={\n",
    "            \"company\": company,\n",
    "            \"items\": parse_response.text\n",
    "        },\n",
    "        context={\"company\": company},\n",
    "        citations=news_response.citations\n",
    "    )\n",
    "    review_response.save_to_file(base_dir=response_file_path, variable=company)\n",
    "\n",
    "for company in companies:\n",
    "    company_news_chain(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276eff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prompt_chain.utils.loader:Loaded 16 responses from ../outputs/responses\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from projects.monday_briefing.utils.pdf_exporter import generate_summary_pdf, generate_pdf_from_markdown\n",
    "\n",
    "# 1. Load and combine reviews\n",
    "review_lists = [\n",
    "    NewsReviewList.from_dict(response.structured)\n",
    "    for response in load_prompt_responses(\n",
    "        directory=response_file_path,\n",
    "        filename_pattern='news_review*04-25T*.json'\n",
    "    )\n",
    "]\n",
    "\n",
    "combined = reduce(lambda a, b: a.join(b), review_lists) if review_lists else NewsReviewList(items=[])\n",
    "\n",
    "# 2. filter to only those you want\n",
    "summary_only = combined.filter_by_include(True)\n",
    "\n",
    "# 3. Group the summaries by topic\n",
    "organized_reviews = summary_only.organize_by_category(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for topic, review_list in organized_reviews.items():\n",
    "    news_items = []\n",
    "    for i in review_list.items:\n",
    "        sources = '\\n'.join([f\"{s}\" for s in i.sources])\n",
    "        news_item = f\"{i.summary}\\nsources:{sources}\"\n",
    "        news_items.append(news_item)\n",
    "\n",
    "    news_item_string = '\\n\\n'.join(news_items)\n",
    "\n",
    "    #Parse news\n",
    "    response = llm.run_prompt(\n",
    "        prompt=summary_prompt,\n",
    "        variables={\n",
    "            \"topic\": topic,\n",
    "            \"news_items\": news_item_string\n",
    "        },\n",
    "        context={\"topic\": topic}\n",
    "    )\n",
    "    response.save_to_file(base_dir=response_file_path, variable=topic, print_save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f65fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Usage\n",
       "```\n",
       "Completion Tokens:   436\n",
       "Prompt Tokens:       708\n",
       "Total Tokens:        1,144\n",
       "Estimated Cost:      $0.006130\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Response Metadata\n",
       "| Field | Value |\n",
       "|---|---|\n",
       "| Model | gpt-4o |\n",
       "| Temperature | 0.3 |\n",
       "| Max Tokens | 2048 |\n",
       "| Top-K | 40 |\n",
       "| Top-P | 0.9 |\n",
       "| Created | 2025-04-27 21:44:23+00:00 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Output\n",
       "```\n",
       "```json\n",
       "{\n",
       "  \"topic\": \"Products\",\n",
       "  \"summary\": [\n",
       "    \"Keyston Brothers launched the final additions to their Podium Collection, enhancing their luxury automotive interior offerings with high-end leathers and fabrics[1][2].\",\n",
       "    \"S&F Supplies introduced the HP Latex R530 All-in-One Printer, focusing on innovative and space-efficient printing solutions, and launched the Avery Dennison Auravate Decorative Window Film Series, featuring seven premium films for glass enhancements[3].\",\n",
       "    \"Trivantage announced the BatylineÂ® Sling Fabric Collection, offering two distinct collections from Serge Ferrari, which expands their performance fabric offerings and reinforces their market position in technical textiles[4][5].\",\n",
       "    \"United Fabrics introduced 'Blocker,' a new product with a unique embossed texture mimicking sewn leather, and continues to focus on the 'Red Rocks' collection created in collaboration with Sunbrella, inspired by the American Southwest with 24 SKUs of performance fabrics in earth-toned colorways[6][7][8].\"\n",
       "  ],\n",
       "  \"sources\": [\n",
       "    \"https://www.thehogring.com/2025/04/10/keyston-bros-debuts-final-podium-collection-leathers/\",\n",
       "    \"https://keystonbros.com/blogs\",\n",
       "    \"https://sfsupplies.com/news/\",\n",
       "    \"https://www.textileworld.com/textile-world/nonwovens-technical-textiles/2025/04/trivantage-launches-batyline-sling-fabric-collection-two-distinct-collections-from-serge-ferrari/\",\n",
       "    \"https://casualnewsnow.com/blog/2025/04/09/trivantage-launches-batyline-sling-fabric-collection/\",\n",
       "    \"https://www.instagram.com/p/DI1x5XhTGxX/\",\n",
       "    \"https://www.unitedfabrics.com\",\n",
       "    \"https://www.textileworld.com/textile-world/2024/10/united-fabrics-and-sunbrella-look-to-the-southwest-for-new-red-rocks-collection/\"\n",
       "  ]\n",
       "}\n",
       "```\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from projects.monday_briefing.utils.pdf_exporter import generate_topic_summary_pdf\n",
    "\n",
    "# 1. Load and combine reviews\n",
    "summary_lists = [\n",
    "    SummaryResponseList.from_dict(response.structured)\n",
    "    for response in load_prompt_responses(\n",
    "        directory=response_file_path,\n",
    "        filename_pattern='news_review*04-25T*.json'\n",
    "    )\n",
    "]\n",
    "\n",
    "combined = reduce(lambda a, b: a.join(b), summary_lists) if summary_lists else SummaryResponseList(items=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd2132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
